---
layout:     post
title:      "Private Data Aggregation on a Budget"
subtitle:   "Secure Federated Learning for Sporadic Devices"
date:       2019-01-02 12:00:00
author:     "Morten Dahl"
header-img: "img/post-bg-01.jpg"
summary:    "What happens when you want to do secure multiparty computation but you are the only party motivated in investing resources in it? In this blog post we walk through a simple protocol for secure aggregation for federated learning, explaining the how and why of several cryptographic techniques."
---

<em><strong>TL;DR:</strong> What happens when you want to do secure multiparty computation but you're the only party that's really interested in investing resources in it? In this blog post we'll step through a simple solution for federated learning we came up with a few years ago.</em> 

Secure multiparty computation (MPC) is an amazing technology when you need to ensure privacy in computations: you essentially have a bunch of parties that each have a data set they wish to keep private, yet using these techniques they can still evaluate a function on the joint data sets and only reveal the output.



[paper](https://eprint.iacr.org/2017/643) and several presentations

joint work done at Snips with Mathieu and Valerio

been wanting to write this blog post for a while

this came out at about the same time as Google's secure aggregation paper; where they were training neural networks by averaging gradients, we wanted to generate global prior distributions for recommendations (see paper for more use cases)



in this post i want to not only show how it works but also how we built it

# Motivation

## Aggregation


# Secure Distributed Aggregation

each `xi` is known only locally by user `ui` but for convenience below we here store them in a list

```python
# each `xi` is known only locally by user `ui`
x = [x1, x2, x3, x4, x5]
```

our goal is for the output receiver to only learn `sum(x)` and no one else anything

BUT WHAT CAN BE LEARNED FROM OUTPUT

```python
class OutputReceiver
```

## Fully decentralised approach

Someone with a background in secure multi-party computation may immediately jump on this as a simple application of an old technique: [secret sharing](/2017/06/04/secret-sharing-part1/). Concretely, with e.g. five users one could easily imagine the flow illustrated in the following figure and detailed next.

<img src="/assets/sda/slides.001.jpeg">

In the first step each user `ui` secret shares their vector `xi` into a list `si = share(xi)` consisting of five shares `si1, ..., si5`.

```python
# xi is known only by ui
assert x == [x1, x2, x3, x4, x5]

for xi in x:
    # executed locally by user ui
    si = share(xi)
```

These shares are then distributed to the other users, sending `si1` to `u1`, `si2` to `u2`, and so on. As a result each user ends up holding a list `ti` of five shares `s1i`, `s2i`, ..., `s5i`, one of which generated by themself (`sii` to be precise) and four of which received from the others.

```python
# only ui knows all values in si
assert s == [s1, s2, s3, s4, s5]

# users distribute shares
t = zip(*s)
```

One way to visualize this is by writing all 25 shares as a 5x5 matrix, with `s1`, `s2`, ..., `s5` making up the rows and `t1`, `t2`, ..., `t5` making up the columns.

(visualize matrix)

Next, each user `ui` applies a homomorphic property of the secret sharing scheme to aggregate the five shares they hold in `ti`, which in our case simply amount to summing them.

```python
# only ui knows all values in ti
assert t == [t1, t2, t3, t4, t5]

for ti in t:
    # executed locally by user ui
    ri = sum(ti) % Q
```

Having done so we end up with a total of five shares `r1`, `r2`, ..., `r5`, which are finally sent to the output receiver and used for reconstructing `sum(x)`.

```python
# only the output receiver knows all values in r
assert r = [r1, r2, r3, r4, r5]

# executed locally by the output receiver
y = reconstruct(r)

assert y == sum(x)
```


```python
class FullyDecentralisedUser:

    def __init__(self, x):
        self.x = x

    def generate_shares(self):
        self.outgoing_shares = additive_share(self.x)

    def distribute_shares(self, receivers)



u1 = FullyDecentralisedUser(x1)
u2 = FullyDecentralisedUser(x2)
u3 = FullyDecentralisedUser(x3)
u4 = FullyDecentralisedUser(x4)
u5 = FullyDecentralisedUser(x5)

users = [u1, u2, u3, u4, u5]
```

This works and provides very strong privacy guarantees: using an [additive secret sharing sharing](/2017/06/04/secret-sharing-part1/#additive-sharing) means that privacy of `xi` is guaranteed even if all other users are colluding.  ... are guaranteed even if give us perfect privacy

it unfortunately also has a serious problem if we were to use it across e.g. the internet, where users are somewhat sporadic. In particular, the distribution of shares represents a significant synchronization point between all users, where even a single one of them can bring the protocol to a halt by failing to send their shares.



## The server-aided model

A typical solution to the above is what is known as the server-aided model. Here, instead of running the protocol directly between the users, we run it between a smaller set of more reliable servers. 

Note that this changes the trust model: before each user only had to trust themselves but now they have to trust the servers.

 is now run between a small set of servers  select no longer run between the users but  computation  set up may in particular feel like the right fit here as it is probably a good idea to limit the amount of synchronization between users as much as possible. Concretely, one could easily imagine the following: 

1. each user secret shares their vector `x` into shares `s1, s2, s3 = share(x)`; with `N` users we hence end up with a total of `3*N` shares
2. each user then distribute their shares to three servers,   them to a small set of servers who uses homomorphic properties of the secret sharing scheme to perform an aggregation on the individual shares, before finally revealing only the aggregated shares to the intended output receiver, thereby allowing him to reconstruct only the aggregate.

<img src="/assets/sda/slides.001.jpeg">
(update photo to use generic servers instead of clerks)

```python
class Server:

    pass

class User(InputProvider):

class InputProvider:


```

2. Each user then uses a homomorphic property of the secret sharing scheme to aggregate his five shares. Concretely, when our aggregation is a summation he simply adds the shares obtaining `y = s1 + ... + 
  three servers,   them to a small set of servers who uses homomorphic properties of the secret sharing scheme to perform an aggregation on the individual shares, before finally revealing only the aggregated shares to the intended output receiver, thereby allowing him to reconstruct only the aggregate.

```python

shares

```


we were quick to say "secret sharing" but as Nigel later phrased it <em>the problem is to find someone to play with</em>


## Introducing clerks

<img src="/assets/sda/slides.001.jpeg">

Switch to threshold secret sharing scheme to mitigate clerk availability: lower recovery threshold

Means privacy threshold drops as well, so enough clerks coming together could learn values

```python
def shamir_share(threshold)

```

```python
class SimpleClerk(Server):
    pass
```

## Recovering privacy via blinding

no amount of clerks on their own can learn anything; now need privacy threshold together with output receiver

<img src="/assets/sda/slides.002.jpeg">

<img src="/assets/sda/slides.002.jpeg">
(with PRG)

## Improving availability

<img src="/assets/sda/slides.003.jpeg">

```python
class BulletinBoard:

    def put(self, sender, receiver, message):

    def get(self, sender, receiver):
```

## Scaling to any number of users

<img src="/assets/sda/slides.004.jpeg">

## Detecting cheating clerks

<img src="/assets/sda/slides.005.jpeg">

## Further optimizations

packed PHE for reducing data transfer

packed SS for scaling with ???

efficient sharing etc

See paper

input polution

DP

# Alternatives

## Correlated randomness

Used in sensor networks

## Differential privacy